{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e39063",
   "metadata": {},
   "source": [
    "# ADS 509 Module 3: Group Comparison \n",
    "\n",
    "The task of comparing two groups of text is fundamental to textual analysis. There are innumerable applications: survey respondents from different segments of customers, speeches by different political parties, words used in Tweets by different constituencies, etc. In this assignment you will build code to effect comparisons between groups of text data, using the ideas learned in reading and lecture.\n",
    "\n",
    "This assignment asks you to analyze the lyrics and Twitter descriptions for the two artists you selected in Module 1. If the results from that pull were not to your liking, you are welcome to use the zipped data from the ‚ÄúAssignment Materials‚Äù section. Specifically, you are asked to do the following: \n",
    "\n",
    "* Read in the data, normalize the text, and tokenize it. When you tokenize your Twitter descriptions, keep hashtags and emojis in your token set. \n",
    "* Calculate descriptive statistics on the two sets of lyrics and compare the results. \n",
    "* For each of the four corpora, find the words that are unique to that corpus. \n",
    "* Build word clouds for all four corpora. \n",
    "\n",
    "Each one of the analyses has a section dedicated to it below. Before beginning the analysis there is a section for you to read in the data and do your cleaning (tokenization and normalization). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e65f73",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe420bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from wordcloud import WordCloud \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a9f064bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use this space for any additional import statements you need\n",
    "#!pip install wordcloud\n",
    "#!pip install sklearn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "bcbe6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place any addtional functions or constants you need here. \n",
    "\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "# It's handy to have a full set of emojis\n",
    "all_language_emojis = set()\n",
    "\n",
    "for country in emoji.UNICODE_EMOJI : \n",
    "    for em in emoji.UNICODE_EMOJI[country] : \n",
    "        all_language_emojis.add(em)\n",
    "\n",
    "# and now our functions\n",
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity, and num_tokens most common\n",
    "        tokens. Return a list of \n",
    "    \"\"\"\n",
    "\n",
    "    # Fill in the correct values here.\n",
    "    tokes = tokens.split()\n",
    "    num_tokens = sum(map(len, (s.split() for s in tokes)))\n",
    "    num_unique_tokens = len(set(w.lower() for w in tokes))\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = sum(list(map(len, tokes)))\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    \n",
    "def is_emoji(s):\n",
    "    return(s in all_language_emojis)\n",
    "\n",
    "def contains_emoji(s):\n",
    "    \n",
    "    s = str(s)\n",
    "    emojis = [ch for ch in s if is_emoji(ch)]\n",
    "\n",
    "    return(len(emojis) > 0)\n",
    "\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    # modify this function to remove stopwords\n",
    "    tokens_wo_sw = [word for word in tokens if not word in sw]\n",
    "    return(tokens_wo_sw)\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    \n",
    "    # modify this function to return tokens\n",
    "    text = text.split()\n",
    "    return(text)\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47735524",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "Use this section to ingest your data into the data structures you plan to use. Typically this will be a dictionary or a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "ff88201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel fre to use the below cells as an example or read in the data in a way you prefer\n",
    "\n",
    "data_location = \"/users/lenny/\" # change to your location if it is not in the same directory as your notebook\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "artist_files = {'mtrench':'mtrench_followers_data.txt',\n",
    "                'NateWantsToBtl':'NateWantsToBtl_followers_data.txt'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "df415d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv(data_location + twitter_folder + artist_files['mtrench'],\n",
    "                           sep=\"\\t\",\n",
    "                           quoting=3)\n",
    "\n",
    "twitter_data['artist'] = \"mtrench\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "966804cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_2 = pd.read_csv(data_location + twitter_folder + artist_files['NateWantsToBtl'],\n",
    "                             sep=\"\\t\",\n",
    "                             quoting=3)\n",
    "twitter_data_2['artist'] = \"NateWantsToBtl\"\n",
    "\n",
    "twitter_data = pd.concat([\n",
    "    twitter_data,twitter_data_2])\n",
    "    \n",
    "del(twitter_data_2)\n",
    "twitter_data = twitter_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "f28f1293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Friend Count</th>\n",
       "      <th>Description</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flatprobably</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1491491320778608642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>aaa</td>\n",
       "      <td>mtrench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lennyj89</td>\n",
       "      <td>Leonard Littleton</td>\n",
       "      <td>250520140</td>\n",
       "      <td>Mount Sterling, KY</td>\n",
       "      <td>57.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mtrench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KenishaShannon8</td>\n",
       "      <td>Kenisha Shannon</td>\n",
       "      <td>1511854002207608842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>Kenisha . 17üçÜ . Join me on DMüå∑</td>\n",
       "      <td>mtrench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BrookeFrein</td>\n",
       "      <td>Brooke Frein</td>\n",
       "      <td>1508824619637256196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>Brooke . 19ü§ç . Just have funüôè</td>\n",
       "      <td>mtrench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CourtenayPeder</td>\n",
       "      <td>Courtenay Peterson</td>\n",
       "      <td>228472111</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>92.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>ur mom is a dad joke. Her/She/x</td>\n",
       "      <td>mtrench</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Screen Name                Name                   ID  \\\n",
       "0     Flatprobably                Flat  1491491320778608642   \n",
       "1         lennyj89   Leonard Littleton            250520140   \n",
       "2  KenishaShannon8     Kenisha Shannon  1511854002207608842   \n",
       "3      BrookeFrein        Brooke Frein  1508824619637256196   \n",
       "4   CourtenayPeder  Courtenay Peterson            228472111   \n",
       "\n",
       "             Location  Follower Count  Friend Count  \\\n",
       "0                 NaN             0.0           6.0   \n",
       "1  Mount Sterling, KY            57.0         221.0   \n",
       "2                 NaN             5.0         593.0   \n",
       "3                 NaN            16.0         722.0   \n",
       "4    British Columbia            92.0         353.0   \n",
       "\n",
       "                       Description   artist  \n",
       "0                              aaa  mtrench  \n",
       "1                              NaN  mtrench  \n",
       "2   Kenisha . 17üçÜ . Join me on DMüå∑  mtrench  \n",
       "3    Brooke . 19ü§ç . Just have funüôè  mtrench  \n",
       "4  ur mom is a dad joke. Her/She/x  mtrench  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "674767d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the lyrics here\n",
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "lyrics_data_list = []\n",
    "\n",
    "for artist in artist_folders : \n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    for f_name in artist_files : \n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile:\n",
    "            lines = infile.read().replace('\\n', ' ')\n",
    "            lines.replace('\\n', '')\n",
    "            text = re.split(r'\\s{3,}', lines)\n",
    "            lyrics_data_list.append((artist, text[0], text[1]))\n",
    "\n",
    "lyrics_data = pd.DataFrame(lyrics_data_list, columns = ['artist', 'title', 'lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "cb8c3eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marianas trench</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>In the house I grew up in My room in the basem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marianas trench</td>\n",
       "      <td>Alibis</td>\n",
       "      <td>From the scrapes and bruises To the familiar a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marianas trench</td>\n",
       "      <td>Alive Again</td>\n",
       "      <td>I felt it turn to come and go Don't worry no o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marianas trench</td>\n",
       "      <td>All To Myself</td>\n",
       "      <td>I don't patronize, I realize I'm losing and, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marianas trench</td>\n",
       "      <td>And So It Goes</td>\n",
       "      <td>In every heart There is a room A sanctuary is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist           title  \\\n",
       "0  marianas trench          Acadia   \n",
       "1  marianas trench          Alibis   \n",
       "2  marianas trench     Alive Again   \n",
       "3  marianas trench   All To Myself   \n",
       "4  marianas trench  And So It Goes   \n",
       "\n",
       "                                              lyrics  \n",
       "0  In the house I grew up in My room in the basem...  \n",
       "1  From the scrapes and bruises To the familiar a...  \n",
       "2  I felt it turn to come and go Don't worry no o...  \n",
       "3  I don't patronize, I realize I'm losing and, t...  \n",
       "4  In every heart There is a room A sanctuary is ...  "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9892d14",
   "metadata": {},
   "source": [
    "## Tokenization and Normalization\n",
    "\n",
    "In this next section, tokenize and normalize your data. We recommend the following cleaning. \n",
    "\n",
    "**Lyrics** \n",
    "\n",
    "* Remove song titles\n",
    "* Casefold to lowercase\n",
    "* Remove punctuation\n",
    "* Split on whitespace\n",
    "* Remove stopwords (optional)\n",
    "\n",
    "Removal of stopwords is up to you. Your descriptive statistic comparison will be different if you include stopwords, though TF-IDF should still find interesting features for you.\n",
    "\n",
    "**Twitter Descriptions** \n",
    "\n",
    "* Casefold to lowercase\n",
    "* Remove punctuation other than emojis or hashtags\n",
    "* Split on whitespace\n",
    "* Remove stopwords\n",
    "\n",
    "Removing stopwords seems sensible for the Twitter description data. Remember to leave in emojis and hashtags, since you analyze those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "5ca379eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the `pipeline` techniques from BTAP Ch 1 or 5\n",
    "\n",
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]\n",
    "\n",
    "lyrics_data[\"tokens\"] = lyrics_data[\"lyrics\"].apply(prepare,pipeline=my_pipeline)\n",
    "lyrics_data[\"num_tokens\"] = lyrics_data[\"tokens\"].map(len) \n",
    "\n",
    "twitter_data[\"tokens\"] = twitter_data[\"Description\"].apply(prepare,pipeline=my_pipeline)\n",
    "twitter_data[\"num_tokens\"] = twitter_data[\"tokens\"].map(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "614498ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = twitter_data.dropna()\n",
    "twitter_data = twitter_data.reset_index()\n",
    "twitter_data = twitter_data.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "68af8650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Friend Count</th>\n",
       "      <th>Description</th>\n",
       "      <th>artist</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CourtenayPeder</td>\n",
       "      <td>Courtenay Peterson</td>\n",
       "      <td>228472111</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>92.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>ur mom is a dad joke. Her/She/x</td>\n",
       "      <td>mtrench</td>\n",
       "      <td>[ur, mom, dad, joke, hershex]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d73m</td>\n",
       "      <td>Donna Y</td>\n",
       "      <td>40288440</td>\n",
       "      <td>Scotland, United Kingdom</td>\n",
       "      <td>78.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>A life without music would be a lonely place. ...</td>\n",
       "      <td>mtrench</td>\n",
       "      <td>[life, without, music, would, lonely, place, l...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grimoiretheband</td>\n",
       "      <td>Grimoire is a band!</td>\n",
       "      <td>1238646768126038017</td>\n",
       "      <td>Ontario, Canada</td>\n",
       "      <td>151.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>We‚Äôre a group of 5 angsty teenagers from Missi...</td>\n",
       "      <td>mtrench</td>\n",
       "      <td>[we‚Äôre, group, 5, angsty, teenagers, mississau...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alicat613</td>\n",
       "      <td>Ali Bowie</td>\n",
       "      <td>66555002</td>\n",
       "      <td>Ottawa, Ontario</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>Festival Producer üé∂üíïüêæüåª Booking for #OGF2023 - ...</td>\n",
       "      <td>mtrench</td>\n",
       "      <td>[festival, producer, üé∂üíïüêæüåª, booking, #ogf2023, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WittleSquish</td>\n",
       "      <td>Squish</td>\n",
       "      <td>1099159332850024450</td>\n",
       "      <td>British Columbia, Canada</td>\n",
       "      <td>24.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Semi-nerdy Canadian who likes to stream and is...</td>\n",
       "      <td>mtrench</td>\n",
       "      <td>[seminerdy, canadian, likes, stream, funny, ma...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Screen Name                 Name                   ID  \\\n",
       "0   CourtenayPeder   Courtenay Peterson            228472111   \n",
       "1             d73m              Donna Y             40288440   \n",
       "2  grimoiretheband  Grimoire is a band!  1238646768126038017   \n",
       "3        Alicat613            Ali Bowie             66555002   \n",
       "4     WittleSquish               Squish  1099159332850024450   \n",
       "\n",
       "                   Location  Follower Count  Friend Count  \\\n",
       "0          British Columbia            92.0         353.0   \n",
       "1  Scotland, United Kingdom            78.0         424.0   \n",
       "2           Ontario, Canada           151.0         550.0   \n",
       "3           Ottawa, Ontario           697.0        1054.0   \n",
       "4  British Columbia, Canada            24.0          73.0   \n",
       "\n",
       "                                         Description   artist  \\\n",
       "0                    ur mom is a dad joke. Her/She/x  mtrench   \n",
       "1  A life without music would be a lonely place. ...  mtrench   \n",
       "2  We‚Äôre a group of 5 angsty teenagers from Missi...  mtrench   \n",
       "3  Festival Producer üé∂üíïüêæüåª Booking for #OGF2023 - ...  mtrench   \n",
       "4  Semi-nerdy Canadian who likes to stream and is...  mtrench   \n",
       "\n",
       "                                              tokens  num_tokens  \n",
       "0                      [ur, mom, dad, joke, hershex]           5  \n",
       "1  [life, without, music, would, lonely, place, l...           9  \n",
       "2  [we‚Äôre, group, 5, angsty, teenagers, mississau...          18  \n",
       "3  [festival, producer, üé∂üíïüêæüåª, booking, #ogf2023, ...           9  \n",
       "4  [seminerdy, canadian, likes, stream, funny, ma...           8  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "6cf534be",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['has_emoji'] = twitter_data[\"Description\"].apply(contains_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec69ac9",
   "metadata": {},
   "source": [
    "Let's take a quick look at some descriptions with emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0a5a0512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>Description</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19434</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>for legal reasons everything i post is a joke üíñ</td>\n",
       "      <td>[legal, reasons, everything, post, joke, üíñ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32324</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>probably at foodland // grayden üççüíñ</td>\n",
       "      <td>[probably, foodland, grayden, üççüíñ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121525</th>\n",
       "      <td>NateWantsToBtl</td>\n",
       "      <td>I really like food,ouat,maximum ride, ,underta...</td>\n",
       "      <td>[really, like, foodouatmaximum, ride, undertal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53012</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>I love catsüòªüòªüòªüò∏üò∏üò∏</td>\n",
       "      <td>[love, catsüòªüòªüòªüò∏üò∏üò∏]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>23 years old ‚úåüèº\\\\ Cree Native ‚úäüèº// üá®üá¶ // üòºMin ...</td>\n",
       "      <td>[23, years, old, ‚úåüèº, cree, native, ‚úäüèº, üá®üá¶, üòºmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>·¥¨À° ∞·µò·µê·µà·µòÀ°‚Å±À°À°·µÉ ∞ ·∂†·µí ≥ ·µâ·µõ·µâ ≥ ∏·µó ∞‚Å±‚Åø·µç ‚ù§</td>\n",
       "      <td>[·¥¨À° ∞·µò·µê·µà·µòÀ°‚Å±À°À°·µÉ ∞, ·∂†·µí ≥, ·µâ·µõ·µâ ≥ ∏·µó ∞‚Å±‚Åø·µç, ‚ù§]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24619</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>I have 1000 hobbies and no time Art: @arcaneba...</td>\n",
       "      <td>[1000, hobbies, time, art, arcanebat, next, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79859</th>\n",
       "      <td>NateWantsToBtl</td>\n",
       "      <td>personal account‚Ä¢ mostly just a big sad üò≠‚Ä¢ i s...</td>\n",
       "      <td>[personal, account‚Ä¢, mostly, big, sad, üò≠‚Ä¢, som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>F.B.G.Müòù</td>\n",
       "      <td>[fbgmüòù]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>mtrench</td>\n",
       "      <td>A good book and a great cup of coffee are a ne...</td>\n",
       "      <td>[good, book, great, cup, coffee, necessity, üñ§]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                                        Description  \\\n",
       "19434          mtrench    for legal reasons everything i post is a joke üíñ   \n",
       "32324          mtrench                 probably at foodland // grayden üççüíñ   \n",
       "121525  NateWantsToBtl  I really like food,ouat,maximum ride, ,underta...   \n",
       "53012          mtrench                                  I love catsüòªüòªüòªüò∏üò∏üò∏   \n",
       "4546           mtrench  23 years old ‚úåüèº\\\\ Cree Native ‚úäüèº// üá®üá¶ // üòºMin ...   \n",
       "253            mtrench                     ·¥¨À° ∞·µò·µê·µà·µòÀ°‚Å±À°À°·µÉ ∞ ·∂†·µí ≥ ·µâ·µõ·µâ ≥ ∏·µó ∞‚Å±‚Åø·µç ‚ù§   \n",
       "24619          mtrench  I have 1000 hobbies and no time Art: @arcaneba...   \n",
       "79859   NateWantsToBtl  personal account‚Ä¢ mostly just a big sad üò≠‚Ä¢ i s...   \n",
       "7558           mtrench                                           F.B.G.Müòù   \n",
       "3842           mtrench  A good book and a great cup of coffee are a ne...   \n",
       "\n",
       "                                                   tokens  \n",
       "19434         [legal, reasons, everything, post, joke, üíñ]  \n",
       "32324                   [probably, foodland, grayden, üççüíñ]  \n",
       "121525  [really, like, foodouatmaximum, ride, undertal...  \n",
       "53012                                  [love, catsüòªüòªüòªüò∏üò∏üò∏]  \n",
       "4546    [23, years, old, ‚úåüèº, cree, native, ‚úäüèº, üá®üá¶, üòºmi...  \n",
       "253                   [·¥¨À° ∞·µò·µê·µà·µòÀ°‚Å±À°À°·µÉ ∞, ·∂†·µí ≥, ·µâ·µõ·µâ ≥ ∏·µó ∞‚Å±‚Åø·µç, ‚ù§]  \n",
       "24619   [1000, hobbies, time, art, arcanebat, next, co...  \n",
       "79859   [personal, account‚Ä¢, mostly, big, sad, üò≠‚Ä¢, som...  \n",
       "7558                                              [fbgmüòù]  \n",
       "3842       [good, book, great, cup, coffee, necessity, üñ§]  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data[twitter_data.has_emoji].sample(10)[[\"artist\",\"Description\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c55c9",
   "metadata": {},
   "source": [
    "With the data processed, we can now start work on the assignment questions. \n",
    "\n",
    "Q: What is one area of improvement to your tokenization that you could theoretically carry out? (No need to actually do it; let's not make perfect the enemy of good enough.)\n",
    "\n",
    "A: I think if we were able to tokenize the data as we read it in, it would be more efficient.  Currently, we are iterating through the data a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1594271",
   "metadata": {},
   "source": [
    "## Calculate descriptive statistics on the two sets of lyrics and compare the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "dc25e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statists for marianas trench are:\n",
      "There are 10849 tokens in the data.\n",
      "There are 1580 unique tokens in the data.\n",
      "There are 85874 characters in the data.\n",
      "The lexical diversity is 0.146 in the data.\n",
      "\n",
      "\n",
      "The statists for nate wants to battle are:\n",
      "There are 35789 tokens in the data.\n",
      "There are 4211 unique tokens in the data.\n",
      "There are 281605 characters in the data.\n",
      "The lexical diversity is 0.118 in the data.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "for artist in artist_folders:\n",
    "    #create a temporary list of tokens through all sets of songs by artist\n",
    "    temp_tokens = lyrics_data['tokens'].loc[lyrics_data['artist'] == artist]\n",
    "    \n",
    "    #create a list to store each token from each song\n",
    "    token_list = []\n",
    "    if artist == 'marianas trench':\n",
    "        for i in range(len(temp_tokens)):\n",
    "            for token in temp_tokens[i]:\n",
    "                token_list.append(token)\n",
    "    if artist == 'nate wants to battle':\n",
    "        for i in range(71 ,len(temp_tokens)):\n",
    "            for token in temp_tokens[i]:\n",
    "                token_list.append(token)\n",
    "    \n",
    "    #create a string object of the list\n",
    "    string_list = str(token_list)\n",
    "    \n",
    "    #generate the descriptive stats\n",
    "    print(\"The statists for \" + artist + \" are:\")\n",
    "    descriptive_stats(string_list, verbose=True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2ada9",
   "metadata": {},
   "source": [
    "Q: what observations do you make about these data? \n",
    "\n",
    "A: Nate Wants to Battle has many more songs than Marianas Trench.  It seems that as the number of unique tokens goes up, the lower the lexical diversty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750aa526",
   "metadata": {},
   "source": [
    "## Find tokens uniquely related to a corpus\n",
    "\n",
    "Typically we would use TF-IDF to find unique tokens in documents. Unfortunately, we either have too few documents, if we view each data source as a single document, or too many, if we view each description as a separate document. In the latter case, our problem will be that descriptions tend to be short, so our matrix would be too sparse to support analysis. \n",
    "\n",
    "To get around this, we find tokens for each corpus that match the following criteria:\n",
    "\n",
    "1. The token appears at least `n` times in all corpora\n",
    "1. The tokens are in the top 10 for the highest ratio of appearances in a given corpora vs appearances in other corpora.\n",
    "\n",
    "You will choose a cutoff for yourself based on the side of the corpus you're working with. If you're working with the Robyn-Cher corpora provided, `n=5` seems to perform reasonably well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "9002bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokensOverThreshold(word_list, threshold):\n",
    "    new_word_list = []\n",
    "    unique_word_list = []\n",
    "    corpora_length = len(word_list)\n",
    "    corpora_wordcount = Counter(word_list)\n",
    "    \n",
    "    for word in word_list:\n",
    "        new_word_list.append((word, corpora_wordcount[word], corpora_length, threshold))\n",
    "    \n",
    "    for tokes in new_word_list:\n",
    "        if tokes not in unique_word_list:\n",
    "            unique_word_list.append(tokes)\n",
    "    \n",
    "    df = pd.DataFrame(unique_word_list, columns = ['token', 'corpus_count', 'corpus_tokens', 'cutoff'])\n",
    "    return df.sort_values(by=['corpus_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "ce72f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "#define a list for each corpus\n",
    "\n",
    "#Marianas Trench Lyrics\n",
    "corp1 = lyrics_data['tokens'].loc[lyrics_data['artist'] == 'marianas trench']\n",
    "corpus1 = []\n",
    "for i in range(len(corp1)):\n",
    "    for token in corp1[i]:\n",
    "        corpus1.append(token)\n",
    "\n",
    "#Nate Wants to Battle Lyrics\n",
    "corp2 = lyrics_data['tokens'].loc[lyrics_data['artist'] == 'nate wants to battle']\n",
    "corpus2 = []\n",
    "for i in range(71, len(corp2)):\n",
    "    for token in corp2[i]:\n",
    "        corpus2.append(token)\n",
    "\n",
    "#Marianas Trench Twitter Descriptions\n",
    "corp3 = twitter_data['Description'].loc[twitter_data['artist'] == 'mtrench']\n",
    "corpus3 = []\n",
    "for i in range(len(corp3)):\n",
    "    for token in corp3[i].split():\n",
    "        corpus3.append(token)\n",
    "\n",
    "#Nate Wants to Battle Twitter Descriptions\n",
    "corp4 = twitter_data['Description'].loc[twitter_data['artist'] == 'NateWantsToBtl']\n",
    "corpus4 = []\n",
    "for i in range(73130, len(corp4)):\n",
    "    for token in corp4[i].split():\n",
    "        corpus4.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "3d48eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>corpus_count</th>\n",
       "      <th>corpus_tokens</th>\n",
       "      <th>cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>know</td>\n",
       "      <td>254</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>dont</td>\n",
       "      <td>236</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>im</td>\n",
       "      <td>169</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>like</td>\n",
       "      <td>152</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>love</td>\n",
       "      <td>150</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ill</td>\n",
       "      <td>128</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>cant</td>\n",
       "      <td>124</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>one</td>\n",
       "      <td>120</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>never</td>\n",
       "      <td>107</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>get</td>\n",
       "      <td>104</td>\n",
       "      <td>10849</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  corpus_count  corpus_tokens  cutoff\n",
       "92    know           254          10849      50\n",
       "91    dont           236          10849      50\n",
       "87      im           169          10849      50\n",
       "138   like           152          10849      50\n",
       "335   love           150          10849      50\n",
       "65     ill           128          10849      50\n",
       "190   cant           124          10849      50\n",
       "16     one           120          10849      50\n",
       "68   never           107          10849      50\n",
       "120    get           104          10849      50"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1_df = tokensOverThreshold(corpus1, 50)\n",
    "corpus1_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "88c0306b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>corpus_count</th>\n",
       "      <th>corpus_tokens</th>\n",
       "      <th>cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>im</td>\n",
       "      <td>818</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>dont</td>\n",
       "      <td>459</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>know</td>\n",
       "      <td>442</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>ill</td>\n",
       "      <td>384</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>youre</td>\n",
       "      <td>362</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>like</td>\n",
       "      <td>330</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>see</td>\n",
       "      <td>327</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>cant</td>\n",
       "      <td>321</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>320</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>never</td>\n",
       "      <td>282</td>\n",
       "      <td>35789</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  corpus_count  corpus_tokens  cutoff\n",
       "347     im           818          35789      50\n",
       "77    dont           459          35789      50\n",
       "58    know           442          35789      50\n",
       "358    ill           384          35789      50\n",
       "233  youre           362          35789      50\n",
       "82    like           330          35789      50\n",
       "232    see           327          35789      50\n",
       "207   cant           321          35789      50\n",
       "0       go           320          35789      50\n",
       "302  never           282          35789      50"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2_df = tokensOverThreshold(corpus2, 50)\n",
    "corpus2_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "46dc39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus3_df = tokensOverThreshold(corpus3, 50)\n",
    "corpus3_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "7dae665a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>corpus_count</th>\n",
       "      <th>corpus_tokens</th>\n",
       "      <th>cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>|</td>\n",
       "      <td>2747</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and</td>\n",
       "      <td>2017</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I</td>\n",
       "      <td>1392</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>1256</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>to</td>\n",
       "      <td>962</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of</td>\n",
       "      <td>933</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the</td>\n",
       "      <td>825</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>my</td>\n",
       "      <td>690</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>‚Ä¢</td>\n",
       "      <td>620</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>||</td>\n",
       "      <td>532</td>\n",
       "      <td>83716</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  corpus_count  corpus_tokens  cutoff\n",
       "60      |          2747          83716      50\n",
       "17    and          2017          83716      50\n",
       "33      I          1392          83716      50\n",
       "7       a          1256          83716      50\n",
       "128    to           962          83716      50\n",
       "12     of           933          83716      50\n",
       "10    the           825          83716      50\n",
       "205    my           690          83716      50\n",
       "53      ‚Ä¢           620          83716      50\n",
       "824    ||           532          83716      50"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus4_df = tokensOverThreshold(corpus4, 50)\n",
    "corpus4_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca4aa05",
   "metadata": {},
   "source": [
    "Q: What are some observations about the top tokens? Do you notice any interesting items on the list? \n",
    "\n",
    "A: It seems that the top tokens are repeated across different corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f52b3",
   "metadata": {},
   "source": [
    "## Build word clouds for all four corpora. \n",
    "\n",
    "For building wordclouds, we'll follow exactly the code of the text. The code in this section can be found [here](https://github.com/blueprints-for-text-analytics-python/blueprints-text/blob/master/ch01/First_Insights.ipynb). If you haven't already, you should absolutely clone the repository that accompanies the book. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "786b2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def wordcloud(word_freq, title=None, max_words=200, stopwords=None):\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, \n",
    "                   background_color= \"black\", colormap=\"Paired\", \n",
    "                   max_font_size=150, max_words=max_words)\n",
    "    \n",
    "    # convert data frame into dict\n",
    "    if type(word_freq) == pd.Series:\n",
    "        counter = Counter(word_freq.fillna(0).to_dict())\n",
    "    else:\n",
    "        counter = word_freq\n",
    "\n",
    "    # filter stop words in frequency counter\n",
    "    if stopwords is not None:\n",
    "        counter = {token:freq for (token, freq) in counter.items() \n",
    "                              if token not in stopwords}\n",
    "    wc.generate_from_frequencies(counter)\n",
    " \n",
    "    plt.title(title) \n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "def count_words(df, column='tokens', preprocess=None, min_freq=2):\n",
    "\n",
    "    # process tokens and update counter\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # create counter and run through all data\n",
    "    counter = Counter()\n",
    "    df[column].map(update)\n",
    "\n",
    "    # transform counter into data frame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    \n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "c9078cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>im</th>\n",
       "      <td>17467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>14282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>9662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‚Ä¢</th>\n",
       "      <td>8318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gfl</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arianna</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòúüòé</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sham</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ukeuro</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41403 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq\n",
       "token         \n",
       "im       17467\n",
       "love     14282\n",
       "music     9662\n",
       "‚Ä¢         8318\n",
       "life      7945\n",
       "...        ...\n",
       "gfl          2\n",
       "arianna      2\n",
       "üòúüòé           2\n",
       "sham         2\n",
       "ukeuro       2\n",
       "\n",
       "[41403 rows x 1 columns]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(twitter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "c8ef4b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>im</th>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont</th>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ill</th>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youre</th>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purse</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spilled</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terrible</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amends</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3116 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq\n",
       "token         \n",
       "im        1249\n",
       "dont       819\n",
       "know       807\n",
       "ill        594\n",
       "youre      569\n",
       "...        ...\n",
       "shop         2\n",
       "purse        2\n",
       "spilled      2\n",
       "terrible     2\n",
       "amends       2\n",
       "\n",
       "[3116 rows x 1 columns]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(lyrics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a2e53",
   "metadata": {},
   "source": [
    "Q: What observations do you have about these (relatively straightforward) wordclouds? \n",
    "\n",
    "A: Couldn't get the wordcloud code to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a94aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
